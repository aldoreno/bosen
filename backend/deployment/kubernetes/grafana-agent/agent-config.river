logging {
  level  = "info"
  format = "logfmt"
}

otelcol.receiver.otlp "default" {
	// https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.receiver.otlp/

	// configures the default grpc endpoint "0.0.0.0:4317"
	grpc { }
	// configures the default http/protobuf endpoint "0.0.0.0:4318"
	http { }

	output {
		traces  = [otelcol.processor.batch.default.input]
		metrics = [otelcol.processor.batch.default.input]
	}
}

otelcol.processor.batch "default" {
	// https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.processor.batch/
	output {
		traces  = [
			otelcol.exporter.otlp.grafana_apm_tempo.input,
			otelcol.exporter.otlp.grafana_cloud_tempo.input,
		]
		metrics = [
			otelcol.exporter.prometheus.mimir.input,
		]
	}
}

otelcol.exporter.otlp "grafana_apm_tempo" {
	// https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.exporter.otlp/
	client {
		endpoint = env("GRAFANA_APM_TEMPO_ENDPOINT")

		// https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.auth.headers/#example
		auth     = otelcol.auth.headers.grafana_apm_tempo.handler

		tls {
			insecure = true
			insecure_skip_verify = true
		}
	}
}

otelcol.auth.headers "grafana_apm_tempo" {
	header {
		key = "X-Scope-OrgID"
		value = "otelcol-cluster-staging"
	}
}

otelcol.exporter.otlp "grafana_cloud_tempo" {
	// https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.exporter.otlp/
	client {
		endpoint = env("GRAFANA_CLOUD_TEMPO_ENDPOINT")
		auth     = otelcol.auth.basic.grafana_cloud_tempo.handler
	}
}

otelcol.auth.basic "grafana_cloud_tempo" {
	// https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.auth.basic/
	username = env("GRAFANA_CLOUD_TEMPO_USERNAME")
	password = env("GRAFANA_CLOUD_TEMPO_API_KEY")
}

otelcol.exporter.prometheus "mimir" {
	forward_to = [
		prometheus.remote_write.grafana_apm_mimir.receiver,
		prometheus.remote_write.grafana_cloud_mimir.receiver,
	]
}

prometheus.remote_write "grafana_apm_mimir" {
	endpoint {
		url = env("GRAFANA_APM_MIMIR_ENDPOINT")
		headers = {
			"X-Scope-OrgID" = "otelcol-cluster-staging",
		}
	}
}

prometheus.remote_write "grafana_cloud_mimir" {
	endpoint {
		url = env("GRAFANA_CLOUD_MIMIR_ENDPOINT")
		
		basic_auth {
			username = env("GRAFANA_CLOUD_MIMIR_USERNAME")
			password = env("GRAFANA_CLOUD_MIMIR_API_KEY")
		}
	}
}

prometheus.scrape "grafana_agents" {
	targets = [
		{"__address__" = "localhost:80"},
	]

	forward_to = [
		prometheus.remote_write.grafana_apm_mimir.receiver,
		prometheus.remote_write.grafana_cloud_mimir.receiver,
	]
}

// --------

discovery.kubernetes "k8s" {
  role = "pod"

  // Limit searched k8s pods by its namespace
  // src: https://grafana.com/docs/agent/latest/flow/reference/components/discovery.kubernetes/#limit-searched-namespaces-and-filter-by-labels-value
  selectors {
    role = "pod"
    label = "app=bosen-backend"
  }

  namespaces {
	names = ["default"]
  }
}

discovery.relabel "k8s" {
  targets = discovery.kubernetes.k8s.targets

  rule {
    // discovery.kubernetes component's pod role produces many labels
    // see: https://grafana.com/docs/agent/latest/flow/reference/components/discovery.kubernetes/#pod-role
    // following are 2 of many:
    // 1. __meta_kubernetes_namespace: The namespace of the pod object.
    // 2. __meta_kubernetes_pod_label_<labelname>: Each label from the pod object.
    // basically we are mapping: job=<pod.namespace>/<pod.label.name>
    source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_label_app"]
    target_label  = "job"
    separator     = "/"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
    target_label  = "__path__"
    separator     = "/"
    replacement   = "/var/log/pods/*$1/*.log"
  }
}

local.file_match "pods" {
  path_targets = discovery.relabel.k8s.output
}

loki.source.file "pods" {
  targets = local.file_match.pods.targets
  forward_to = [loki.echo.example.receiver]
}

loki.echo "example" { }
